{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owilab/Documents/YacineB/Code/damage_prediction_AE/.venv/lib/python3.10/site-packages/torchdata/datapipes/__init__.py:18: UserWarning: \n",
      "################################################################################\n",
      "WARNING!\n",
      "The 'datapipes', 'dataloader2' modules are deprecated and will be removed in a\n",
      "future torchdata release! Please see https://github.com/pytorch/data/issues/1196\n",
      "to learn more and leave feedback.\n",
      "################################################################################\n",
      "\n",
      "  deprecation_warning()\n",
      "/home/owilab/Documents/YacineB/Code/damage_prediction_AE/.venv/lib/python3.10/site-packages/dask/dataframe/__init__.py:49: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/home/owilab/Documents/YacineB/Code/damage_prediction_AE/.venv/lib/python3.10/site-packages/torch/utils/data/datapipes/utils/common.py:149: UserWarning: Local function is not supported by pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n",
      "/home/owilab/Documents/YacineB/Code/damage_prediction_AE/.venv/lib/python3.10/site-packages/torch/utils/data/datapipes/utils/common.py:157: UserWarning: Lambda function is not supported by pickle, please use regular python function or functools.partial instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from config import settings\n",
    "from torchdata.datapipes import iter as it\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from src.data_preprocessing.utils import (\n",
    "    is_path_excluded,\n",
    "    extract_turbine_name,\n",
    "    add_interval_start_dask,\n",
    "    extract_fs,\n",
    "    filter_based_on_len,\n",
    "    group_data,\n",
    "    collate_data,\n",
    "    convert_dict_to_tuples,\n",
    "    )\n",
    "import dask.dataframe as dd\n",
    "from functools import partial\n",
    "from src.data_preprocessing import preprocessing_function as pf\n",
    "FS = 31.25\n",
    "\n",
    "# Initialize the FileLister DataPipe\n",
    "dp_filename = it.FileLister(root=settings.path.raw, recursive=True, masks='*.parquet.gzip')\n",
    "\n",
    "# Apply the filter to exclude paths containing 'Trash'\n",
    "func_filter = partial(is_path_excluded, exclude_words='Trash')\n",
    "dp_filtered = dp_filename.filter(func_filter)\n",
    "func_filter = partial(is_path_excluded, exclude_words='wierddata')\n",
    "dp_filtered = dp_filtered.filter(func_filter)\n",
    "\n",
    "\n",
    "# Fork the filtered DataPipe into two separate DataPipes\n",
    "dp_forked = dp_filtered.fork(num_instances=2)\n",
    "\n",
    "# Create dp_turbine_name from the first fork\n",
    "dp_turbine_name = dp_forked[0].map(extract_turbine_name)\n",
    "\n",
    "# Create dp_file from the second fork\n",
    "dp_file = dp_forked[1].map(dd.read_parquet)\n",
    "dp_file = dp_file.map(add_interval_start_dask)\n",
    "dp_file = dp_file.map(lambda x: x.compute())\n",
    "\n",
    "# Apply filtering based on length\n",
    "filter_based_on_len_partial = partial(filter_based_on_len, required_len=FS*60*60)\n",
    "dp_file = dp_file.filter(filter_based_on_len_partial)\n",
    "\n",
    "# Combine the two DataPipes using Zipper\n",
    "dp_file_all = it.Zipper(dp_file, dp_turbine_name)\n",
    "dp_file_all = dp_file_all.map(group_data)\n",
    "\n",
    "# Batch the combined DataPipe\n",
    "dp = dp_file_all.batch(50)\n",
    "dp = dp.map(collate_data)\n",
    "processing_module = pf.ParallelModule([\n",
    "    pf.Welch(n_fft=1024),\n",
    "    pf.RMS(),\n",
    "    pf.RollingAverage(window_size=int(FS/2)),\n",
    "    pf.Range(),\n",
    "    pf.Mean(),\n",
    "])\n",
    "def process_data(data):\n",
    "    shape = data['signal'].shape\n",
    "    process_data = processing_module(torch.from_numpy(data['signal'].reshape(-1, shape[-1])))\n",
    "    for key in process_data.keys():\n",
    "        process_data[key] = process_data[key].numpy().reshape(*shape[:-1],-1)\n",
    "    data.update(process_data)\n",
    "    data.pop('signal')\n",
    "    return data\n",
    "\n",
    "def reshape_data(data):    \n",
    "    data = {k: v.reshape(v.shape[0]*v.shape[1],*v.shape[2:]) for k,v in data.items()}\n",
    "    return data\n",
    "\n",
    "def unravel_sensor_name(data):\n",
    "    sensor_axes = data['sensor_name'][0]\n",
    "    new_data = {}\n",
    "    for transform in processing_module.module_dict.keys():\n",
    "        for i, sensor in enumerate(sensor_axes):\n",
    "            new_data[f'{transform}_{sensor}'] = data[transform][...,i,:]\n",
    "    new_data['timestamp'] = data['timestamp']\n",
    "    new_data['turbine_name'] = data['turbine_name']\n",
    "    return new_data\n",
    "        \n",
    "def array_to_bytes(data, columns:list):\n",
    "    for column in columns:\n",
    "        data_col = data[column]\n",
    "        data_col = data_col.astype(np.float32)\n",
    "        data_col = [arr.tobytes() for arr in data_col]\n",
    "        data[column] = data_col\n",
    "    rest_columns = list(set(data.keys())-set(columns))\n",
    "    for column in rest_columns:\n",
    "        data[column] = data[column].flatten().tolist()\n",
    "    return data\n",
    "\n",
    "columns = ['Welch','RollingAverage']\n",
    "columns = [f'{transform}_{sensor}' for transform in columns for sensor in ['X','Y','Z']]\n",
    "array_to_bytes_partial = partial(array_to_bytes, columns=columns)\n",
    "\n",
    "\n",
    "dp = dp.map(process_data)\n",
    "dp = dp.map(reshape_data)\n",
    "dp = dp.map(unravel_sensor_name)\n",
    "dp = dp.map(array_to_bytes_partial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x783f4239bc40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3 \n",
    "from pathlib import Path\n",
    "from src.data_preprocessing import queries \n",
    "\n",
    "dir_database = Path(settings.path.processed)\n",
    "dir_database.mkdir(exist_ok=True, parents=True)\n",
    "path_database = dir_database / 'norther.db'\n",
    "conn = sqlite3.connect(path_database)\n",
    "c = conn.cursor()\n",
    "c.execute(queries.CREATE_PROCCESSED_DATA_TABLE)\n",
    "c.execute(queries.CREATE_METADATA_TABLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n",
      "Record inserted\n"
     ]
    }
   ],
   "source": [
    "for record in dp:\n",
    "    record = convert_dict_to_tuples(record,queries.ORDERED_COLUMNS_PROCESSED)\n",
    "    \n",
    "    c.executemany(queries.INSERT_PROCESSED_DATA, record) \n",
    "    print('Record inserted')\n",
    "conn.commit()\n",
    "\n",
    "     \n",
    "# Commit the changes and close the connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_axis = processing_module.module_dict['Welch'].get_frequency_axis(FS)\n",
    "frequency_axis = frequency_axis.numpy()\n",
    "frequency_axis = np.asarray(frequency_axis, dtype=np.float32).tobytes()\n",
    "metadata = {\n",
    "    'frequency_axis': [frequency_axis],\n",
    "    'sample_rate': [FS],\n",
    "    'window_size': ['10min'],\n",
    "    'processing_method': [processing_module.__str__()]\n",
    "}\n",
    "record = convert_dict_to_tuples(metadata,['frequency_axis', 'sample_rate', 'window_size', 'processing_method'])\n",
    "\n",
    "conn.execute(queries.CREATE_METADATA_TABLE)\n",
    "conn.executemany(queries.INSERT_METADATA, record)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
